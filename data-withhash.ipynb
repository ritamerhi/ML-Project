{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f8f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "import joblib\n",
    "\n",
    "import hashlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52e547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Data Shape\n",
      "(2007, 3)\n",
      "\n",
      "Max Timestamp per Asset for Interval: 30m\n",
      "Gold: 2025-12-02 21:30:00+00:00\n",
      "Silver: 2025-12-02 21:30:00+00:00\n",
      "CAD: 2025-12-02 21:30:00+00:00\n",
      "\n",
      "SHA256 hash of train indices:\n",
      "f54223762806886622699cb167e262fd629156cb1a2ecff43bb4cdf469a1c86b\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "log_file = \"data_log.txt\"\n",
    "\n",
    "def log(msg):\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{timestamp} {msg}\\n\")\n",
    "\n",
    "\n",
    "interval = \"30m\"\n",
    "\n",
    "tickers = {\"Gold\": \"GC=F\", \"Silver\": \"SI=F\", \"CAD\": \"CADUSD=X\"}\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=60)\n",
    "end_date = \"2025-12-03\"\n",
    "\n",
    "log(f\"Interval {interval}\")\n",
    "log(f\"Downloading data from {start_date} to {end_date}\")\n",
    "\n",
    "dfs = {}\n",
    "for name, ticker in tickers.items():\n",
    "    log(f\"Downloading {name} ({ticker})...\")\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, interval=interval, auto_adjust=False)\n",
    "    df = df[[\"Close\"]].rename(columns={\"Close\": name})\n",
    "    dfs[name] = df\n",
    "    log(f\"{name} data shape: {df.shape}\")\n",
    "\n",
    "\n",
    "# Merge & clean\n",
    "all_prices = dfs[\"Gold\"].join([dfs[\"Silver\"], dfs[\"CAD\"]], how=\"outer\")\n",
    "all_prices = all_prices.ffill().bfill()\n",
    "\n",
    "log(f\"Merged dataframe shape: {all_prices.shape}\")\n",
    "\n",
    "print(\"Loaded Data Shape\")\n",
    "print(all_prices.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# MAX TIMESTAMP PER ASSET\n",
    "# ===========================================================\n",
    "print(f\"Max Timestamp per Asset for Interval: {interval}\")\n",
    "log(\"Logging maximum timestamps per asset:\")\n",
    "\n",
    "for asset in [\"Gold\", \"Silver\", \"CAD\"]:\n",
    "    max_ts = all_prices[asset].dropna().index.max()\n",
    "    print(f\"{asset}: {max_ts}\")\n",
    "    log(f\"{asset} max timestamp: {max_ts}\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# TRAIN/TEST SPLIT + HASH TRAIN INDICES\n",
    "# ===========================================================\n",
    "test_ratio = 0.2\n",
    "split_idx = int(len(all_prices) * (1 - test_ratio))\n",
    "\n",
    "train_indices = list(all_prices.index[:split_idx])\n",
    "test_indices  = list(all_prices.index[split_idx:])\n",
    "\n",
    "log(f\"Train size: {len(train_indices)}, Test size: {len(test_indices)}\")\n",
    "\n",
    "# Convert timestamps to strings for hashing\n",
    "train_idx_str = json.dumps([str(ts) for ts in train_indices]).encode()\n",
    "\n",
    "# SHA256\n",
    "train_hash = hashlib.sha256(train_idx_str).hexdigest()\n",
    "\n",
    "# Save train indices to a raw JSON file\n",
    "with open(\"train_indices.json\", \"w\") as f:\n",
    "    json.dump([str(ts) for ts in train_indices], f, indent=2)\n",
    "\n",
    "log(f\"SHA256 Hash of train indices: {train_hash}\")\n",
    "\n",
    "\n",
    "print(\"SHA256 hash of train indices:\")\n",
    "print(train_hash)\n",
    "print()\n",
    "\n",
    "log(\"=== END RUN ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f54789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
